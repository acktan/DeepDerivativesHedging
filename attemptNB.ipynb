{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bbaa97c-4665-4184-86bd-eee9a0f3c225",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "import os\n",
    "import seaborn\n",
    "from tqdm import tqdm\n",
    "\n",
    "trainPath = 'data/Dataset_1_train_asset.csv'\n",
    "targetPath = 'data/Dataset_1_train_payoff.csv'\n",
    "testPath = 'data/Dataset_1_test_asset.csv'\n",
    "growthPath = 'data/Dataset_1_train_asset_daily growth_rate.csv'\n",
    "\n",
    "trainData = pd.read_csv(trainPath, header=None)\n",
    "testData = pd.read_csv(testPath, header=None)\n",
    "target = pd.read_csv(targetPath, header=None)\n",
    "growthTrain = pd.read_csv(growthPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b69ff54-2d50-41cf-aa06-54563ac07755",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exercise 1 - BlackScholes Model\n",
    "\n",
    "N = norm.cdf\n",
    "\n",
    "def bs_call(K: float, #underlying asset's price\n",
    "            T: float, #time till maturity\n",
    "            S: float = 1.0, # strike price\n",
    "            r: float = 0.0,  # risk-free\n",
    "            sigma: float = 0.158):\n",
    "    \n",
    "    d1 = (np.log(S/K) + (r + 0.5 * sigma**2)*T) / (sigma*np.sqrt(T))\n",
    "    d2 = d1 - sigma * np.sqrt(T)\n",
    "    return S * N(d1) - K * np.exp(-r*T) * N(d2), N(-d1)\n",
    "\n",
    "def bs_put(K: float, #underlying asset's price\n",
    "           T: float, #time till maturity\n",
    "           S: float = 1.0, #strike price\n",
    "           r: float = 0.0, # risk-free\n",
    "           sigma: float = 0.158):\n",
    "    \n",
    "    d1 = (np.log(S/K) + (r + 0.5 * sigma**2)*T) / (sigma*np.sqrt(T))\n",
    "    d2 = d1 - sigma * np.sqrt(T)\n",
    "    return K*np.exp(-r*T)*N(-d2) - S*N(-d1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e8302c-7a43-4d13-b742-85200e9aefcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_hedge(df: pd.DataFrame):\n",
    "    deltas = pd.DataFrame(index=range(df.shape[0]),columns=range(df.shape[1]))\n",
    "    \n",
    "    for i in tqdm(range(0, df.shape[0])):\n",
    "        short_position = 0.0\n",
    "        for j in range(0, df.shape[1]):\n",
    "            S = 100\n",
    "            initial_price = 100\n",
    "            K = df.loc[i, :].values[j]\n",
    "            T = (31 - j)/365\n",
    "            result, delta = bs_call(K=K, T=T, S=S)\n",
    "            short_position += -result\n",
    "            deltas.loc[i, j] = delta\n",
    "\n",
    "    return deltas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db539c2a-7790-4a52-a217-c828d93b519d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def col_numeric_names(df):\n",
    "    df = df.rename(columns={x:y for x,y in zip(df.columns,range(0,len(df.columns)))})\n",
    "    return df\n",
    "\n",
    "def absolute_growth(df):\n",
    "    len_df = df.shape[1]\n",
    "    temp = df.iloc[:,1:len_df]\n",
    "    temp = col_numeric_names(temp)\n",
    "    temp2 = df.iloc[:,:len_df-1]\n",
    "    df2 = temp-temp2\n",
    "    df2.insert(0, \"0\", 0)\n",
    "    df2 = col_numeric_names(df2)\n",
    "    return df2\n",
    "growthTrain = absolute_growth(trainData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd555956-637f-474b-9cf9-7b2046b8f42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bs_deltas = calculate_hedge(trainData)\n",
    "bs_deltas_test = calculate_hedge(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb362b25-4ebe-4bab-b86d-d0b6ef106cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# multi in and output RNN attempt:\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "torch.manual_seed(42)\n",
    "# Set up device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define stock price path, payoffs, and transaction costs\n",
    "S_list = torch.Tensor(trainData.values.tolist())\n",
    "S_test = torch.Tensor(testData.values.tolist())\n",
    "payoffs = torch.Tensor([item for sublist in target.values for item in sublist])\n",
    "transaction_costs = torch.Tensor([0.0] * S_list.shape[0])\n",
    "transaction_costs_test = torch.Tensor([0.0] * S_test.shape[0])\n",
    "growths = torch.Tensor(growthTrain.values.tolist())\n",
    "\n",
    "# Set hyperparameters\n",
    "batch_size = 256\n",
    "num_epochs = 50\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Set up dataset and iterator\n",
    "dataset_train = torch.utils.data.TensorDataset(S_list[0:7999], payoffs[0:7999], transaction_costs[0:7999], growths[0:7999])\n",
    "dataset_val = torch.utils.data.TensorDataset(S_list[7999:], payoffs[7999:], transaction_costs[7999:], growths[7999:])\n",
    "dataset_test = torch.utils.data.TensorDataset(S_test, transaction_costs)\n",
    "train_loader = torch.utils.data.DataLoader(dataset_train, batch_size=batch_size, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(dataset_val, batch_size=batch_size, shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(dataset_test, batch_size=1, shuffle=False)\n",
    "\n",
    "class DeltaRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(DeltaRNN, self).__init__()\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, num_layers=1, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, S):\n",
    "        #S = S.unsqueeze(1)\n",
    "        rnn_out, _ = self.rnn(S)\n",
    "        delta_nn_output = self.fc(rnn_out)\n",
    "        return delta_nn_output.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a22f60-c777-4976-9531-0d806d5595b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BS_PnLLoss(torch.nn.Module):\n",
    "    def __init__(self, beta=1):\n",
    "        super(BS_PnLLoss, self).__init__()\n",
    "        self.beta = beta\n",
    "        self.q1 = torch.tensor((0.), dtype=torch.float32, requires_grad=True, device=device)\n",
    "        self.q2 = torch.tensor((0.), dtype=torch.float32, requires_grad=True, device=device)\n",
    "\n",
    "    def forward(self, predicted, true, growth):\n",
    "        # calculate delta_nn_output\n",
    "        S_delta_T = torch.transpose(growth, 0, 1)\n",
    "        zeros = torch.zeros((predicted.shape[0], 1)).to(device)\n",
    "        delta_nn_output = torch.cat([zeros, predicted.squeeze(-1)], dim=1)\n",
    "        delta_S = torch.diagonal(torch.matmul(delta_nn_output, S_delta_T))\n",
    "        # calculate CT\n",
    "        c = 0 # for now with black scholes\n",
    "        CT = c * torch.sum(torch.abs(torch.diff(delta_nn_output, dim=1)))\n",
    "        # calculate STK\n",
    "        STK = true\n",
    "        # calculate PnL\n",
    "        PnL = CT + delta_S - STK\n",
    "        L = -PnL\n",
    "        # calculate risk measure\n",
    "        #ES50 = torch.median(L)\n",
    "        #ES99 = np.percentile(L.cpu().detach().numpy(), q=1)\n",
    "        #risk_measure = 1/(1+self.beta) * (ES50 + self.beta * ES99)\n",
    "        es_99 = (F.relu(L-self.q1).mean())/(1-0.99) + self.q1\n",
    "        es_50 = (F.relu(L-self.q2).mean())/(1-0.5) + self.q2\n",
    "        risk_measure = (es_50 + es_99*self.beta)/(1+self.beta)\n",
    "        return risk_measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3de23f5-ceb4-46a0-bd8e-d12c489fb33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import math\n",
    "\n",
    "train_loss = []\n",
    "test_loss = []\n",
    "model = DeltaRNN(1, 16, 1).to(device)\n",
    "# Set up optimizer\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = BS_PnLLoss(beta=1)\n",
    "\n",
    "for epoch in tqdm(range(num_epochs), desc='Training'):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    counter = 0\n",
    "    for S, y, c, g in train_loader:\n",
    "        counter += 1\n",
    "        S = S.to(device).unsqueeze(-1)\n",
    "        S_in = S[:, :-1].to(device)\n",
    "        y = y.to(device)\n",
    "        c = c.to(device)\n",
    "        g = g.to(device)\n",
    "\n",
    "        # Calculate gradients and update model weights\n",
    "        optimizer.zero_grad()\n",
    "        deltas = model(S_in)\n",
    "        losses = criterion(deltas, y, g)\n",
    "        running_loss += losses.item()\n",
    "\n",
    "        losses.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    epoch_train_loss = running_loss / counter\n",
    "    train_loss.append(epoch_train_loss)\n",
    "    print(\"Train loss: {}\".format(epoch_train_loss))\n",
    "    \n",
    "    running_loss_test = 0.0\n",
    "    counter = 0\n",
    "\n",
    "    for S_val, y_val, c_val, g_val in val_loader:\n",
    "        model.eval()\n",
    "        \n",
    "        counter += 1\n",
    "        S_val = S_val.to(device).unsqueeze(-1)\n",
    "        S_in_val = S_val[:, :-1].to(device)\n",
    "        y_val = y_val.to(device)\n",
    "        c_val = c_val.to(device)\n",
    "        g_val = g_val.to(device)\n",
    "\n",
    "        deltas_val = model(S_in_val)\n",
    "        losses_test = criterion(deltas_val, y_val, g_val)\n",
    "        running_loss_test += losses_test.item()\n",
    "\n",
    "    epoch_test_loss = running_loss_test / counter\n",
    "    test_loss.append(epoch_test_loss)\n",
    "    print(\"Test loss: {}\".format(epoch_test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7d459b-6637-464d-b751-a9c389d8a540",
   "metadata": {},
   "outputs": [],
   "source": [
    "final = []\n",
    "for stock, costs in tqdm(test_loader):\n",
    "    stock = stock.to(device).unsqueeze(-1)\n",
    "    costs = costs.to(device)\n",
    "    final.append(model(stock).cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c948564e-a984-415c-9a52-44e55922f22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def StandardData(data: np.ndarray):\n",
    "    min_value = np.min(data)\n",
    "    max_value = np.max(data)\n",
    "    normalized_data = (data - min_value) / (max_value - min_value)\n",
    "    return normalized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8736d634-87b1-4267-98be-649bcda35e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_figures(deltas_BS: pd.DataFrame, rnn_bs: pd.DataFrame, df: pd.DataFrame): \n",
    "    fig, axs = plt.subplots(2, 3)\n",
    "    fig.set_size_inches(18.5, 10.5)\n",
    "    fig.suptitle('Delta spread at different time intervals', size=45)\n",
    "\n",
    "    axs[0,0].plot(df.loc[:, 0], deltas_BS.loc[:, 0], 'bo', label='Black-Scholes')\n",
    "    axs[0,0].plot(df.loc[:, 0], rnn_bs.loc[:, 0], 'gx', label='Delta-RNN')\n",
    "    axs[0,0].legend()\n",
    "    axs[0,0].set_title('Time 0')\n",
    "    axs[0,0].set_ylim([0, 1])\n",
    "    axs[0,1].plot(df.loc[:, 1], deltas_BS.loc[:, 1], 'bo', label='Black-Scholes')\n",
    "    axs[0,1].plot(df.loc[:, 1], StandardData(rnn_bs.loc[:, 1]), 'gx', label='Delta-RNN')\n",
    "    axs[0,1].legend()\n",
    "    axs[0,1].set_title('Time 1')\n",
    "    axs[0,2].plot(df.loc[:, 5], deltas_BS.loc[:, 5], 'bo', label='Black-Scholes')\n",
    "    axs[0,2].plot(df.loc[:, 5], StandardData(rnn_bs.loc[:, 5]), 'gx', label='Delta-RNN')\n",
    "    axs[0,2].legend()\n",
    "    axs[0,2].set_title('Time 5')\n",
    "    axs[1,0].plot(df.loc[:, 15], deltas_BS.loc[:, 15], 'bo', label='Black-Scholes')\n",
    "    axs[1,0].plot(df.loc[:, 15], StandardData(rnn_bs.loc[:, 15]), 'gx', label='Delta-RNN')\n",
    "    axs[1,0].legend()\n",
    "    axs[1,0].set_title('Time 15')\n",
    "    axs[1,1].plot(df.loc[:, 25], deltas_BS.loc[:, 25], 'bo', label='Black-Scholes')\n",
    "    axs[1,1].plot(df.loc[:, 25], StandardData(rnn_bs.loc[:, 25]), 'gx', label='Delta-RNN')\n",
    "    axs[1,1].legend()\n",
    "    axs[1,1].set_title('Time 25')\n",
    "    axs[1,2].plot(df.loc[:, 30], deltas_BS.loc[:, 30], 'bo', label='Black-Scholes')\n",
    "    axs[1,2].plot(df.loc[:, 30], StandardData(rnn_bs.loc[:, 30]), 'gx', label='Delta-RNN')\n",
    "    axs[1,2].legend()\n",
    "    axs[1,2].set_title('Time 30')\n",
    "\n",
    "    for ax in axs.flat:\n",
    "        ax.set(xlabel='Spot price', ylabel='Delta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0855190b-5c69-4806-a584-6baf6e9f96df",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_figures(bs_deltas_test, pd.DataFrame(final), testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e94801-a2f1-441e-9808-1aa72bd25ec7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
