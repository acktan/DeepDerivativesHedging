{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bbaa97c-4665-4184-86bd-eee9a0f3c225",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "import os\n",
    "import seaborn\n",
    "from tqdm import tqdm\n",
    "\n",
    "trainPath1 = 'data/Dataset_2_train_instrument_1.csv'\n",
    "trainPath2 = 'data/Dataset_2_train_instrument_2.csv'\n",
    "\n",
    "targetPath = 'data/Dataset_2_train_payoff.csv'\n",
    "testPath1 = 'data/Dataset_2_test_instrument_1.csv'\n",
    "testPath2 = 'data/Dataset_2_test_instrument_2.csv'\n",
    "\n",
    "growthPath = 'data/Dataset_1_train_asset_daily growth_rate.csv'\n",
    "\n",
    "train1 = pd.read_csv(trainPath1, header=None)\n",
    "train2 = pd.read_csv(trainPath2, header=None)\n",
    "test1 = pd.read_csv(testPath1, header=None)\n",
    "test2 = pd.read_csv(testPath1, header=None)\n",
    "target = pd.read_csv(targetPath, header=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c720734f-959f-4bb1-a1fc-f5a822398168",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define growth values for instrument 1\n",
    "def col_numeric_names(df):\n",
    "    df = df.rename(columns={x:y for x,y in zip(df.columns,range(0,len(df.columns)))})\n",
    "    return df\n",
    "\n",
    "def absolute_growth(df):\n",
    "    len_df = df.shape[1]\n",
    "    temp = df.iloc[:,1:len_df]\n",
    "    temp = col_numeric_names(temp)\n",
    "    temp2 = df.iloc[:,:len_df-1]\n",
    "    df2 = temp-temp2\n",
    "    df2.insert(0, \"0\", 0)\n",
    "    df2 = col_numeric_names(df2)\n",
    "    return df2\n",
    "growthTrain = absolute_growth(train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68fe3f0-b717-4f9d-b6aa-4313016d0b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exercise 2 - Heston Model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "torch.manual_seed(42)\n",
    "# Set up device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define stock price path, payoffs, and transaction costs\n",
    "train_instrument1 = torch.Tensor(train1.values.tolist())\n",
    "train_instrument2 = torch.Tensor(train2.values.tolist())\n",
    "test_instrument1 = torch.Tensor(test1.values.tolist())\n",
    "test_instrument2 = torch.Tensor(test2.values.tolist())\n",
    "\n",
    "payoffs = torch.Tensor([item for sublist in target.values for item in sublist])\n",
    "transaction_costs = torch.Tensor([0.01] * train1.shape[0])\n",
    "transaction_costs_test = torch.Tensor([0.01] * test1.shape[0])\n",
    "growths = torch.Tensor(growthTrain.values.tolist())\n",
    "\n",
    "# define parameters\n",
    "num_epochs = 50\n",
    "batch_size = 256\n",
    "learning_rate = 0.001\n",
    "\n",
    "\n",
    "# Set up dataset and iterator\n",
    "dataset_train = torch.utils.data.TensorDataset(train_instrument1[0:7999], train_instrument2[0:7999], payoffs[0:7999], transaction_costs[0:7999], growths[0:7999])\n",
    "dataset_val = torch.utils.data.TensorDataset(train_instrument1[7999:], train_instrument2[7999:], payoffs[7999:], transaction_costs[7999:], growths[7999:])\n",
    "dataset_test = torch.utils.data.TensorDataset(test_instrument1, test_instrument2, transaction_costs_test)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset_train, batch_size=batch_size, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(dataset_val, batch_size=batch_size, shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(dataset_test, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01977bbc-7673-423d-b7cf-ef3fda479c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import math\n",
    "\n",
    "class DeepHedging_RNN(nn.Module):\n",
    "    def __init__(self, input_size, HL_size, output_size):\n",
    "        super(DeepHedging_RNN, self).__init__()\n",
    "        self.rnn = torch.nn.RNN(input_size=input_size,\n",
    "                                hidden_size=HL_size,\n",
    "                                num_layers=1)\n",
    "        self.linear = torch.nn.Linear(HL_size, output_size)\n",
    "        self.softplus = torch.nn.Softplus()\n",
    "        \n",
    "    def forward(self, S):\n",
    "        out, _ = self.rnn(S)\n",
    "        out = self.linear(out)\n",
    "        out = self.softplus(out)\n",
    "\n",
    "        return out.squeeze()\n",
    "\n",
    "def heston_loss(deltas, S, v, pay_off, growth, costs, q1, q2, beta=1):\n",
    "    zeros = torch.zeros((deltas.shape[0], 1)).to(device)\n",
    "\n",
    "    S_delta_T = torch.transpose(growth, 0, 1)\n",
    "    V_delta_T = torch.transpose(torch.cat([zeros, torch.abs(torch.diff(v.squeeze(-1), dim=1))], dim=1), 0, 1)\n",
    "    \n",
    "    delta_S = torch.diagonal(torch.matmul(deltas, S_delta_T))\n",
    "    delta_V = torch.diagonal(torch.matmul(deltas, V_delta_T))\n",
    "    delta_diff = torch.cat([zeros, torch.abs(torch.diff(deltas, dim=1))], dim=1)\n",
    "    costs_S = costs * torch.diagonal(torch.matmul(delta_diff, S))\n",
    "    costs_V = costs * torch.diagonal(torch.matmul(delta_diff, v))\n",
    "    \n",
    "    # Calculating loss\n",
    "    loss = pay_off.squeeze() - delta_S + costs_S - delta_V + costs_V\n",
    "    es_99 = (F.relu(loss-q1).mean())/(1-0.99) + q1\n",
    "    es_50 = (F.relu(loss-q2).mean())/(1-0.5) + q2\n",
    "    risk_measure = (es_50 + es_99*beta)/(1+beta)\n",
    "    return risk_measure\n",
    "\n",
    "def standardized(tensor):\n",
    "    #tensor = tensor[:, :-1, :]\n",
    "    return (tensor - torch.mean(tensor, 1, True)) / torch.std(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f99ffdb-5cd6-4412-8e87-37103e25b872",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 2 # number of expected features\n",
    "output_size = 1\n",
    "HL_size = 16\n",
    "model = DeepHedging_RNN(input_size, HL_size, output_size).to(device)\n",
    "# Set up optimizer\n",
    "q1 = torch.tensor((0.), dtype=torch.float32, requires_grad=True, device=device)\n",
    "q2 = torch.tensor((0.), dtype=torch.float32, requires_grad=True, device=device)\n",
    "optimizer = optim.Adam(list(model.parameters()) + [q1, q2], lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643423c4-7e46-467b-b30f-3ae516fc528e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "train_loss = []\n",
    "val_loss = []\n",
    "\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    counter = 0\n",
    "\n",
    "    for S, v, y, c, g in train_loader:\n",
    "        counter += 1\n",
    "        S = (S.to(device).unsqueeze(-1))\n",
    "        v = (v.to(device).unsqueeze(-1))\n",
    "        y = y.to(device)\n",
    "        c = c.to(device)\n",
    "        g = g.to(device)\n",
    "        \n",
    "        # Calculate gradients and update model weights\n",
    "        optimizer.zero_grad()\n",
    "        S_v = torch.cat((S, v), 2)\n",
    "        deltas = model(S_v)\n",
    "        losses = heston_loss(deltas, S, v, y, g, c, q1, q2)\n",
    "        running_loss += losses.item()\n",
    "        \n",
    "        losses.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    epoch_train_loss = running_loss / counter\n",
    "    train_loss.append(epoch_train_loss)\n",
    "    print(\"Train loss: {}\".format(epoch_train_loss))\n",
    "    \n",
    "    # validation \n",
    "    running_loss_test = 0.0\n",
    "    counter = 0\n",
    "    model.eval()\n",
    "    for S_val, v_val, y_val, c_val, g_val in val_loader:\n",
    " \n",
    "        \n",
    "        counter += 1\n",
    "        S_val = (S_val.to(device).unsqueeze(-1))\n",
    "        v_val = (v_val.to(device).unsqueeze(-1))\n",
    "        y_val = y_val.to(device)\n",
    "        g_val = g_val.to(device)\n",
    "        c_val = c_val.to(device)\n",
    "        \n",
    "        S_v_val = torch.cat((S_val, v_val), 2)\n",
    "        deltas_val = model(S_v_val)\n",
    "        losses = heston_loss(deltas_val, S_val, v_val, y_val, g_val, c_val, q1, q2)\n",
    "        running_loss_test += losses.item()\n",
    "\n",
    "    epoch_test_loss = running_loss_test / counter\n",
    "    val_loss.append(epoch_test_loss)\n",
    "    print(\"Validation loss: {}\".format(epoch_test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e54dd6a-fd90-4dd2-b54c-26e953f580f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check test set\n",
    "final = []\n",
    "for S_test, sigma_test, _ in tqdm(test_loader):\n",
    "    S_test = S_test.to(device).unsqueeze(-1)\n",
    "    sigma_test = sigma_test.to(device).unsqueeze(-1)\n",
    "    S_sigma = torch.cat((S_test, sigma_test), 2)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        final.append(model(S_sigma).cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03fbdad7-4172-4678-b19c-10445cd5dcab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def StandardData(data: np.ndarray):\n",
    "    min_value = np.min(data)\n",
    "    max_value = np.max(data)\n",
    "    standard_data = (data - min_value) / (max_value - min_value)\n",
    "    return standard_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d3e27a-d847-4c15-a176-8f984137c235",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_figures(greek: pd.DataFrame, \n",
    "                 rnn_bs: pd.DataFrame, \n",
    "                 df: pd.DataFrame): \n",
    "    fig, axs = plt.subplots(2, 3)\n",
    "    fig.set_size_inches(18.5, 10.5)\n",
    "    fig.suptitle('Delta spread at different time intervals: Test Set', size=45)\n",
    "\n",
    "    axs[0,0].plot(df.loc[:, 0], greek.loc[:, 0], 'bo', label='Heston')\n",
    "    axs[0,0].plot(df.loc[:, 0], StandardData(rnn_bs.loc[:, 0]), 'gx', label='Heston-RNN')\n",
    "    axs[0,0].legend()\n",
    "    axs[0,0].set_title('Time 0')\n",
    "    axs[0,0].set_ylim([0, 1])\n",
    "    axs[0,1].plot(df.loc[:, 1], greek.loc[:, 1], 'bo', label='Heston')\n",
    "    axs[0,1].plot(df.loc[:, 1], StandardData(rnn_bs.loc[:, 1]), 'gx', label='Heston-RNN')\n",
    "    axs[0,1].legend()\n",
    "    axs[0,1].set_title('Time 1')\n",
    "    axs[0,2].plot(df.loc[:, 5], greek.loc[:, 5], 'bo', label='Heston')\n",
    "    axs[0,2].plot(df.loc[:, 5], StandardData(rnn_bs.loc[:, 5]), 'gx', label='Heston-RNN')\n",
    "    axs[0,2].legend()\n",
    "    axs[0,2].set_title('Time 5')\n",
    "    axs[1,0].plot(df.loc[:, 15], greek.loc[:, 15], 'bo', label='Heston')\n",
    "    axs[1,0].plot(df.loc[:, 15], StandardData(rnn_bs.loc[:, 15]), 'gx', label='Heston-RNN')\n",
    "    axs[1,0].legend()\n",
    "    axs[1,0].set_title('Time 15')\n",
    "    axs[1,1].plot(df.loc[:, 25], greek.loc[:, 25], 'bo', label='Heston')\n",
    "    axs[1,1].plot(df.loc[:, 25], StandardData(rnn_bs.loc[:, 25]), 'gx', label='Heston-RNN')\n",
    "    axs[1,1].legend()\n",
    "    axs[1,1].set_title('Time 25')\n",
    "    axs[1,2].plot(df.loc[:, 30], greek.loc[:, 30], 'bo', label='Heston')\n",
    "    axs[1,2].plot(df.loc[:, 30], StandardData(rnn_bs.loc[:, 30]), 'gx', label='Heston-RNN')\n",
    "    axs[1,2].legend()\n",
    "    axs[1,2].set_title('Time 30')\n",
    "\n",
    "    for ax in axs.flat:\n",
    "        ax.set(xlabel='Spot price', ylabel='Delta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40985284-682a-43c6-a829-c37e43c34c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "\n",
    "def heston_call_price(S, K, r, T, V0, kappa, theta, sigma, rho):\n",
    "    \n",
    "    \"\"\"\n",
    "    Calculates the price of a European call option using the Heston model for stochastic volatility.\n",
    "    \n",
    "    Parameters:\n",
    "        S: Spot price of the underlying asset\n",
    "        K: Strike price of the option\n",
    "        r: Risk-free interest rate\n",
    "        T: Time to maturity of the option (in years)\n",
    "        V0: Initial volatility\n",
    "        kappa: Mean reversion speed of volatility\n",
    "        theta: Long-term mean of volatility\n",
    "        sigma: Volatility of volatility\n",
    "        rho: Correlation between the underlying asset and volatility processes\n",
    "        \n",
    "    Returns:\n",
    "        The price of the European call option\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define some useful constants\n",
    "    i = 1j\n",
    "    beta = kappa - i*rho*sigma\n",
    "    gamma = np.sqrt(beta**2 + sigma**2)\n",
    "    rho2 = rho**2\n",
    "    a = kappa*theta\n",
    "    b = kappa + gamma\n",
    "    \n",
    "    # Calculate the characteristic function of the log-stock price\n",
    "    u = 0.5\n",
    "    d = np.sqrt((rho2 - 1)**2 + 4*rho2*(sigma**2/(2*gamma))*(kappa - i*rho*sigma + gamma))\n",
    "    g = (beta - rho2 + d) / (2*rho2)\n",
    "    D = (beta - rho2 + d)**2 - 4*rho2*(beta - i*rho*sigma + gamma)\n",
    "    G = (beta - rho2 + d - D) / (4*rho2)\n",
    "    C = r*i*u + a/(sigma**2)*((beta - rho2 + d)*T - 2*np.log((1 - G*np.exp(-d*T))/(1 - G)))\n",
    "    D = (1 - np.exp(-d*T)) / (1 - G*np.exp(-d*T))\n",
    "    B = np.exp(C + D*V0)\n",
    "    \n",
    "    # Calculate the price of the option\n",
    "    d1 = (np.log(S/K) + (r + 0.5*V0) * T) / (np.sqrt(V0*T))\n",
    "    d2 = d1 - np.sqrt(V0*T)\n",
    "    price = S*norm.cdf(d1) - K*np.exp(-r*T)*norm.cdf(d2)\n",
    "    \n",
    "    return price, norm.cdf(d1), d2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e36a8cf-2f08-4ddf-86e9-1671ea413ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_heston(instrument1: pd.DataFrame, \n",
    "                     instrument2: pd.DataFrame,\n",
    "                     K: float=100,\n",
    "                     r: float=0.0,):\n",
    "    \n",
    "    instrument1 = np.array(instrument1)\n",
    "    instrument2 = np.array(instrument2)\n",
    "    # using given data to calculate variables kappa, theta, sigma, rho\n",
    "    V0 = instrument2[0].mean()\n",
    "    Vfinal = instrument2[-1].mean()\n",
    "    theta = V0 + (Vfinal - V0) / instrument2[-1].std()\n",
    "    kappa = 2*(theta - V0) / (Vfinal*instrument2[-1].std())\n",
    "    sigma = 0.2 # assumption\n",
    "    rho = -0.5 # assumption\n",
    "    K=K\n",
    "    \n",
    "    S = instrument1.flatten()\n",
    "    T = (31 - np.arange(instrument1.shape[1]))/365\n",
    "    T = np.tile(T, (instrument1.shape[0],1)).flatten()\n",
    "    _, delta, _ = heston_call_price(S, K, r, T, V0, kappa, theta, sigma, rho)\n",
    "    return delta.reshape(instrument1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d73208f-afd2-4e7c-94fe-6d833bd27b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "heston_deltas_test = pd.DataFrame(calculate_heston(test1, test2))\n",
    "heston_deltas_train = pd.DataFrame(calculate_heston(train1, train2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c72b482-e9d1-42fc-a1ac-c1b4a481d79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_figures(heston_deltas_test, pd.DataFrame(final), test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d217adf3-0a55-4066-81c9-4ce03c3e123f",
   "metadata": {},
   "outputs": [],
   "source": [
    "greek = pd.DataFrame(calculate_heston(train1, train2))\n",
    "df = train1\n",
    "fig, axs = plt.subplots(2, 3)\n",
    "fig.set_size_inches(18.5, 10.5)\n",
    "fig.suptitle('Delta spread at different time intervals: Train set', size=45)\n",
    "\n",
    "axs[0,0].plot(df.loc[:, 0], greek.loc[:, 0], 'bo', label='Heston')\n",
    "axs[0,0].legend()\n",
    "axs[0,0].set_title('Time 0')\n",
    "axs[0,0].set_ylim([0, 1])\n",
    "axs[0,1].plot(df.loc[:, 1], greek.loc[:, 1], 'bo', label='Heston')\n",
    "axs[0,1].legend()\n",
    "axs[0,1].set_title('Time 1')\n",
    "axs[0,2].plot(df.loc[:, 5], greek.loc[:, 5], 'bo', label='Heston')\n",
    "axs[0,2].legend()\n",
    "axs[0,2].set_title('Time 5')\n",
    "axs[1,0].plot(df.loc[:, 15], greek.loc[:, 15], 'bo', label='Heston')\n",
    "axs[1,0].legend()\n",
    "axs[1,0].set_title('Time 15')\n",
    "axs[1,1].plot(df.loc[:, 25], greek.loc[:, 25], 'bo', label='Heston')\n",
    "axs[1,1].legend()\n",
    "axs[1,1].set_title('Time 25')\n",
    "axs[1,2].plot(df.loc[:, 30], greek.loc[:, 30], 'bo', label='Heston')\n",
    "axs[1,2].legend()\n",
    "axs[1,2].set_title('Time 30')\n",
    "\n",
    "for ax in axs.flat:\n",
    "    ax.set(xlabel='Spot price', ylabel='Delta')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
